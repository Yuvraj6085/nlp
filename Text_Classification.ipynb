{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN21IaVPDMXJgDayClGsh9h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yuvraj6085/nlp/blob/main/Text_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "BkuEJAzLnl9d",
        "outputId": "c7e1a2d5-0644-4239-aa0b-62a1c7ceba9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.12), please consider upgrading to the latest version (0.3.13).\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/mfaisalqureshi/spam-email?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 207k/207k [00:00<00:00, 61.0MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n",
            "Path to dataset files: /root/.cache/kagglehub/datasets/mfaisalqureshi/spam-email/versions/1\n",
            "Files in dataset: ['spam.csv']\n",
            "  Category                                            Message\n",
            "0      ham  Go until jurong point, crazy.. Available only ...\n",
            "1      ham                      Ok lar... Joking wif u oni...\n",
            "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
            "3      ham  U dun say so early hor... U c already then say...\n",
            "4      ham  Nah I don't think he goes to usf, he lives aro...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "import os\n",
        "import pandas as pd\n",
        "path = kagglehub.dataset_download(\"mfaisalqureshi/spam-email\")\n",
        "print(\"Path to dataset files:\", path)\n",
        "print(\"Files in dataset:\", os.listdir(path))\n",
        "csv_file = os.path.join(path, \"spam.csv\")\n",
        "df = pd.read_csv(csv_file, encoding=\"latin-1\")\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQ2oqaZboRxy",
        "outputId": "4f33d435-3f92-42ef-cadd-46660371aeff"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Category                                            Message\n",
            "0      ham  Go until jurong point, crazy.. Available only ...\n",
            "1      ham                      Ok lar... Joking wif u oni...\n",
            "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
            "3      ham  U dun say so early hor... U c already then say...\n",
            "4      ham  Nah I don't think he goes to usf, he lives aro...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCDzUZBqpB1R",
        "outputId": "03983ef3-0d29-4897-e14a-f60f2d0b07a8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Category    0\n",
            "Message     0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6BXsyHmpLZY",
        "outputId": "3d6758aa-39a4-4978-9cc6-e589faef94b3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5572, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.duplicated().any().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IY4zGfplpQPb",
        "outputId": "8ee95467-be89-48e5-a306-8e9a7d5d395a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop_duplicates(inplace=True)"
      ],
      "metadata": {
        "id": "GbTG4VUGpXpW"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.duplicated().any()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uG93qOnWpgOh",
        "outputId": "b752abf1-d031-4036-e940-de8d93ec563a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.False_"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Distribution of spam vs. ham"
      ],
      "metadata": {
        "id": "qHTaCzsfpioZ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pt_u3u0eplq8",
        "outputId": "254d5fcc-2ee9-4016-b0d7-2899e82a9465"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Category', 'Message'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "category_column=df['Category'].value_counts()\n",
        "print(category_column)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oReOb3LwpvEl",
        "outputId": "ae2c08f2-2079-4f60-d246-49ac6dc0ffc7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Category\n",
            "ham     4516\n",
            "spam     641\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "65eHvd32p-Ps"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "le=LabelEncoder()"
      ],
      "metadata": {
        "id": "M37mNa_cqPZv"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Category']=le.fit_transform(df['Category'])"
      ],
      "metadata": {
        "id": "mXnDYDhvqVLv"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pR3JG25tqcr6",
        "outputId": "c51e4872-f191-4465-b297-ce446ddc8b0b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Category                                            Message\n",
            "0         0  Go until jurong point, crazy.. Available only ...\n",
            "1         0                      Ok lar... Joking wif u oni...\n",
            "2         1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
            "3         0  U dun say so early hor... U c already then say...\n",
            "4         0  Nah I don't think he goes to usf, he lives aro...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Preprocessing"
      ],
      "metadata": {
        "id": "2MfP94Tjqe5h"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1LowerCasing Text\n",
        "import string"
      ],
      "metadata": {
        "id": "h6wtfpc6qiJd"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Message']=df['Message'].str.lower()\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Wpn5qvtqmwQ",
        "outputId": "ed9e4a5d-4ff2-4d8a-fec9-bb2ee370c225"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Category                                            Message\n",
            "0         0  go until jurong point, crazy.. available only ...\n",
            "1         0                      ok lar... joking wif u oni...\n",
            "2         1  free entry in 2 a wkly comp to win fa cup fina...\n",
            "3         0  u dun say so early hor... u c already then say...\n",
            "4         0  nah i don't think he goes to usf, he lives aro...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2Remove Extra WhiteSpaces"
      ],
      "metadata": {
        "id": "SpY_NGAfqxlp"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Message']=df['Message'].str.strip()\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFJ30qAyq5QM",
        "outputId": "f901f5af-7e00-4630-8d87-22047c19476c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Category                                            Message\n",
            "0         0  go until jurong point, crazy.. available only ...\n",
            "1         0                      ok lar... joking wif u oni...\n",
            "2         1  free entry in 2 a wkly comp to win fa cup fina...\n",
            "3         0  u dun say so early hor... u c already then say...\n",
            "4         0  nah i don't think he goes to usf, he lives aro...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3 Remove HTML Tags\n",
        "from bs4 import BeautifulSoup"
      ],
      "metadata": {
        "id": "y3A60KmQrB_6"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_html_tag(text):\n",
        "    soup=BeautifulSoup(text,'html.parser')\n",
        "    return soup.get_text()\n",
        "df['Message']=df['Message'].apply(remove_html_tag)\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2keWF85rE1R",
        "outputId": "3558b2f4-def8-44d4-e481-a15e1f6fec80"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Category                                            Message\n",
            "0         0  go until jurong point, crazy.. available only ...\n",
            "1         0                      ok lar... joking wif u oni...\n",
            "2         1  free entry in 2 a wkly comp to win fa cup fina...\n",
            "3         0  u dun say so early hor... u c already then say...\n",
            "4         0  nah i don't think he goes to usf, he lives aro...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4 Remove URLs\n",
        "import re"
      ],
      "metadata": {
        "id": "eeC0JPoOs-ak"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_url(text):\n",
        "  return re.sub(r'https?://\\S+|www\\.\\S+','',text)\n",
        "df['Message']=df['Message'].apply(remove_url)\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LaZO0ZLytCGt",
        "outputId": "991180cc-ec06-4522-f5cd-36856c520681"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Category                                            Message\n",
            "0         0  go until jurong point, crazy.. available only ...\n",
            "1         0                      ok lar... joking wif u oni...\n",
            "2         1  free entry in 2 a wkly comp to win fa cup fina...\n",
            "3         0  u dun say so early hor... u c already then say...\n",
            "4         0  nah i don't think he goes to usf, he lives aro...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove Punctuations"
      ],
      "metadata": {
        "id": "PH2-9usLtVti"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "string.punctuation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "kEa73o64tatE",
        "outputId": "8ef7f779-ebb2-46a2-b0e6-3abf9293f938"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "punctuation=string.punctuation\n"
      ],
      "metadata": {
        "id": "obqaHqzkteRQ"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_punctuation(text):\n",
        "  return text.translate(str.maketrans('','',punctuation))\n",
        "df['Message']=df['Message'].apply(remove_punctuation)\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eiV42OT7tmkG",
        "outputId": "9507cadc-1c05-41f7-8621-146b401bbf28"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Category                                            Message\n",
            "0         0  go until jurong point crazy available only in ...\n",
            "1         0                            ok lar joking wif u oni\n",
            "2         1  free entry in 2 a wkly comp to win fa cup fina...\n",
            "3         0        u dun say so early hor u c already then say\n",
            "4         0  nah i dont think he goes to usf he lives aroun...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Special Characters"
      ],
      "metadata": {
        "id": "eZx0hnmWt4r9"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_special_characters(text):\n",
        "  return re.sub(r'[^a-zA-Z0-9\\s]','',text)\n",
        "df['Message']=df['Message'].apply(remove_special_characters)\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36nNTavGt76i",
        "outputId": "03559555-d403-45e9-e879-52c38b70bc87"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Category                                            Message\n",
            "0         0  go until jurong point crazy available only in ...\n",
            "1         0                            ok lar joking wif u oni\n",
            "2         1  free entry in 2 a wkly comp to win fa cup fina...\n",
            "3         0        u dun say so early hor u c already then say\n",
            "4         0  nah i dont think he goes to usf he lives aroun...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove Numeric Values"
      ],
      "metadata": {
        "id": "oqk_leByuAfv"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_numeric(text):\n",
        "    return re.sub(r'\\d+', '', text)\n",
        "df['Message'] = df['Message'].apply(remove_numeric)"
      ],
      "metadata": {
        "id": "4yApZeU3uENT"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndWBuN0XuISk",
        "outputId": "497acf94-eabb-4ca4-9885-72b2bd0c8fdc"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Category                                            Message\n",
            "0         0  go until jurong point crazy available only in ...\n",
            "1         0                            ok lar joking wif u oni\n",
            "2         1  free entry in  a wkly comp to win fa cup final...\n",
            "3         0        u dun say so early hor u c already then say\n",
            "4         0  nah i dont think he goes to usf he lives aroun...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Non-alpha Numeric"
      ],
      "metadata": {
        "id": "Ro8T_tfYuMjJ"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_non_alphanumeric(text):\n",
        "    return re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
        "df['Message'] = df['Message'].apply(remove_non_alphanumeric)"
      ],
      "metadata": {
        "id": "GT6Y-enjuPBr"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Handling ChatWords"
      ],
      "metadata": {
        "id": "cKxE_v5EuSG3"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_words = {\n",
        "    \"AFAIK\": \"As Far As I Know\",\n",
        "    \"AFK\": \"Away From Keyboard\",\n",
        "    \"ASAP\": \"As Soon As Possible\",\n",
        "    \"ATK\": \"At The Keyboard\",\n",
        "    \"ATM\": \"At The Moment\",\n",
        "    \"A3\": \"Anytime, Anywhere, Anyplace\",\n",
        "    \"BAK\": \"Back At Keyboard\",\n",
        "    \"BBL\": \"Be Back Later\",\n",
        "    \"BBS\": \"Be Back Soon\",\n",
        "    \"BFN\": \"Bye For Now\",\n",
        "    \"B4N\": \"Bye For Now\",\n",
        "    \"BRB\": \"Be Right Back\",\n",
        "    \"BRT\": \"Be Right There\",\n",
        "    \"BTW\": \"By The Way\",\n",
        "    \"B4\": \"Before\",\n",
        "    \"B4N\": \"Bye For Now\",\n",
        "    \"CU\": \"See You\",\n",
        "    \"CUL8R\": \"See You Later\",\n",
        "    \"CYA\": \"See You\",\n",
        "    \"FAQ\": \"Frequently Asked Questions\",\n",
        "    \"FC\": \"Fingers Crossed\",\n",
        "    \"FWIW\": \"For What It's Worth\",\n",
        "    \"FYI\": \"For Your Information\",\n",
        "    \"GAL\": \"Get A Life\",\n",
        "    \"GG\": \"Good Game\",\n",
        "    \"GN\": \"Good Night\",\n",
        "    \"GMTA\": \"Great Minds Think Alike\",\n",
        "    \"GR8\": \"Great!\",\n",
        "    \"G9\": \"Genius\",\n",
        "    \"IC\": \"I See\",\n",
        "    \"ICQ\": \"I Seek you (also a chat program)\",\n",
        "    \"ILU\": \"ILU: I Love You\",\n",
        "    \"IMHO\": \"In My Honest/Humble Opinion\",\n",
        "    \"IMO\": \"In My Opinion\",\n",
        "    \"IOW\": \"In Other Words\",\n",
        "    \"IRL\": \"In Real Life\",\n",
        "    \"KISS\": \"Keep It Simple, Stupid\",\n",
        "    \"LDR\": \"Long Distance Relationship\",\n",
        "    \"LMAO\": \"Laugh My A.. Off\",\n",
        "    \"LOL\": \"Laughing Out Loud\",\n",
        "    \"LTNS\": \"Long Time No See\",\n",
        "    \"L8R\": \"Later\",\n",
        "    \"MTE\": \"My Thoughts Exactly\",\n",
        "    \"M8\": \"Mate\",\n",
        "    \"NRN\": \"No Reply Necessary\",\n",
        "    \"OIC\": \"Oh I See\",\n",
        "    \"PITA\": \"Pain In The A..\",\n",
        "    \"PRT\": \"Party\",\n",
        "    \"PRW\": \"Parents Are Watching\",\n",
        "    \"QPSA?\": \"Que Pasa?\",\n",
        "    \"ROFL\": \"Rolling On The Floor Laughing\",\n",
        "    \"ROFLOL\": \"Rolling On The Floor Laughing Out Loud\",\n",
        "    \"ROTFLMAO\": \"Rolling On The Floor Laughing My A.. Off\",\n",
        "    \"SK8\": \"Skate\",\n",
        "    \"STATS\": \"Your sex and age\",\n",
        "    \"ASL\": \"Age, Sex, Location\",\n",
        "    \"THX\": \"Thank You\",\n",
        "    \"TTFN\": \"Ta-Ta For Now!\",\n",
        "    \"TTYL\": \"Talk To You Later\",\n",
        "    \"U\": \"You\",\n",
        "    \"U2\": \"You Too\",\n",
        "    \"U4E\": \"Yours For Ever\",\n",
        "    \"WB\": \"Welcome Back\",\n",
        "    \"WTF\": \"What The F...\",\n",
        "    \"WTG\": \"Way To Go!\",\n",
        "    \"WUF\": \"Where Are You From?\",\n",
        "    \"W8\": \"Wait...\",\n",
        "    \"7K\": \"Sick:-D Laugher\",\n",
        "    \"TFW\": \"That feeling when\",\n",
        "    \"MFW\": \"My face when\",\n",
        "    \"MRW\": \"My reaction when\",\n",
        "    \"IFYP\": \"I feel your pain\",\n",
        "    \"TNTL\": \"Trying not to laugh\",\n",
        "    \"JK\": \"Just kidding\",\n",
        "    \"IDC\": \"I don't care\",\n",
        "    \"ILY\": \"I love you\",\n",
        "    \"IMU\": \"I miss you\",\n",
        "    \"ADIH\": \"Another day in hell\",\n",
        "    \"ZZZ\": \"Sleeping, bored, tired\",\n",
        "    \"WYWH\": \"Wish you were here\",\n",
        "    \"TIME\": \"Tears in my eyes\",\n",
        "    \"BAE\": \"Before anyone else\",\n",
        "    \"FIMH\": \"Forever in my heart\",\n",
        "    \"BSAAW\": \"Big smile and a wink\",\n",
        "    \"BWL\": \"Bursting with laughter\",\n",
        "    \"BFF\": \"Best friends forever\",\n",
        "    \"CSL\": \"Can't stop laughing\"\n",
        "}"
      ],
      "metadata": {
        "id": "HinFUDbAuUa7"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def replace_chat_words(text):\n",
        "    words = text.split()\n",
        "    for i, word in enumerate(words):\n",
        "        if word.lower() in chat_words:\n",
        "            words[i] = chat_words[word.lower()]\n",
        "    return ' '.join(words)\n",
        "df['Message'] = df['Message'].apply(replace_chat_words)"
      ],
      "metadata": {
        "id": "4IHZlBvfudRW"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Handling StopWords\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9Az0C86uhZZ",
        "outputId": "6c8da3d4-a9e0-4c65-e813-2fdffefc3f88"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "def remove_stopwords(text):\n",
        "    words = text.split()\n",
        "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
        "    return ' '.join(filtered_words)\n",
        "df['Message'] = df['Message'].apply(remove_stopwords)"
      ],
      "metadata": {
        "id": "6Pvw224SvVvf"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Emojis"
      ],
      "metadata": {
        "id": "aP3UNhG8v32N"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import emoji"
      ],
      "metadata": {
        "id": "eIwMEj2fvj-Z"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OhOeWe-PvrDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43106cc2",
        "outputId": "f4d4721f-02fe-4c29-e571-622fcc607417"
      },
      "source": [
        "!pip install emoji"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting emoji\n",
            "  Downloading emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n",
            "Downloading emoji-2.14.1-py3-none-any.whl (590 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: emoji\n",
            "Successfully installed emoji-2.14.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9e057823",
        "outputId": "f18d08e6-2341-4e3a-a974-d09b003e2838"
      },
      "source": [
        "def remove_emojis(text):\n",
        "    return emoji.replace_emoji(text, replace='')\n",
        "\n",
        "df['Message'] = df['Message'].apply(remove_emojis)\n",
        "print(df.head())"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Category                                            Message\n",
            "0         0  go jurong point crazy available bugis n great ...\n",
            "1         0                            ok lar joking wif u oni\n",
            "2         1  free entry wkly comp win fa cup final tkts st ...\n",
            "3         0                u dun say early hor u c already say\n",
            "4         0        nah dont think goes usf lives around though\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stemming"
      ],
      "metadata": {
        "id": "DA3zregpv8cV"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer"
      ],
      "metadata": {
        "id": "KA-xQYcVv-fj"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import *\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "xO8bvY9YwFdt"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "porter_stemmer = PorterStemmer()\n",
        "df['Message_stemmed'] = df['Message'].apply(lambda x: ' '.join([porter_stemmer.stem(word) for word in x.split()]))"
      ],
      "metadata": {
        "id": "9uOtrfkLwN8Z"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Building"
      ],
      "metadata": {
        "id": "vqRxqo5DwU8t"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Text Vectorization"
      ],
      "metadata": {
        "id": "tP0G5q2LwY1p"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv = CountVectorizer()\n",
        "X = cv.fit_transform(df['Message_stemmed']).toarray()\n",
        "y = df['Category']"
      ],
      "metadata": {
        "id": "r7LIA-YMwcIg"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Test Split"
      ],
      "metadata": {
        "id": "bNQYj7nBwgpU"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test , y_train, y_test = train_test_split(X,y,test_size = 0.2, random_state = 42)"
      ],
      "metadata": {
        "id": "b87idtvvwrVB"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Call, Fit And Predict The Models"
      ],
      "metadata": {
        "id": "Un_kJ3ewwwKE"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression with tuned parameters\n",
        "lr_model = LogisticRegression(C=0.1, solver='liblinear', max_iter=500)\n",
        "lr_model.fit(X_train, y_train)\n",
        "lr_pred = lr_model.predict(X_test)"
      ],
      "metadata": {
        "id": "uE8GhMD4wyB4"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Multinomial Naive Bayes with tuned parameters\n",
        "mnb_model = MultinomialNB(alpha=0.1)\n",
        "mnb_model.fit(X_train, y_train)\n",
        "mnb_pred = mnb_model.predict(X_test)"
      ],
      "metadata": {
        "id": "mWJrNeZWw5cm"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gaussian Naive Bayes\n",
        "gnb_model = GaussianNB()\n",
        "gnb_model.fit(X_train, y_train)\n",
        "gnb_pred = gnb_model.predict(X_test)"
      ],
      "metadata": {
        "id": "oBI-CZ4Kw8G_"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Support Vector Machines (SVM) with tuned parameters\n",
        "svm_model = SVC(C=10.0, kernel='rbf', gamma='auto')\n",
        "svm_model.fit(X_train, y_train)\n",
        "svm_pred = svm_model.predict(X_test)"
      ],
      "metadata": {
        "id": "R0vriuvmw-Du"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Decision Trees with tuned parameters\n",
        "dt_model = DecisionTreeClassifier(max_depth=10, min_samples_split=5)\n",
        "dt_model.fit(X_train, y_train)\n",
        "dt_pred = dt_model.predict(X_test)"
      ],
      "metadata": {
        "id": "0gDE-6LkxAfT"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forests with tuned parameters\n",
        "rf_model = RandomForestClassifier(n_estimators=100, max_depth=15, min_samples_split=10)\n",
        "rf_model.fit(X_train, y_train)\n",
        "rf_pred = rf_model.predict(X_test)"
      ],
      "metadata": {
        "id": "ad76tH0hxL4f"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradient Boosting Classifier with tuned parameters\n",
        "gb_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.05, max_depth=5)\n",
        "gb_model.fit(X_train, y_train)\n",
        "gb_pred = gb_model.predict(X_test)"
      ],
      "metadata": {
        "id": "0dsSmRz4xON_"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# XGBoost Classifier with tuned parameters\n",
        "xgb_model = XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=5)\n",
        "xgb_model.fit(X_train, y_train)\n",
        "xgb_pred = xgb_model.predict(X_test)"
      ],
      "metadata": {
        "id": "x0yI6W1KxR-F"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Models Evaluation"
      ],
      "metadata": {
        "id": "V-2NgwqtxW3P"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate accuracy, precision and recall for each model\n",
        "lr_accuracy = accuracy_score(y_test, lr_pred)\n",
        "lr_precision = precision_score(y_test, lr_pred, average='weighted')\n",
        "lr_recall = recall_score(y_test, lr_pred, average='weighted')\n",
        "lr_conf_matrix = confusion_matrix(y_test, lr_pred)\n",
        "\n",
        "mnb_accuracy = accuracy_score(y_test, mnb_pred)\n",
        "mnb_precision = precision_score(y_test, mnb_pred, average='weighted')\n",
        "mnb_recall = recall_score(y_test, mnb_pred, average='weighted')\n",
        "mnb_conf_matrix = confusion_matrix(y_test, mnb_pred)\n",
        "\n",
        "gnb_accuracy = accuracy_score(y_test, gnb_pred)\n",
        "gnb_precision = precision_score(y_test, gnb_pred, average='weighted')\n",
        "gnb_recall = recall_score(y_test, gnb_pred, average='weighted')\n",
        "gnb_conf_matrix = confusion_matrix(y_test, gnb_pred)\n",
        "\n",
        "svm_accuracy = accuracy_score(y_test, svm_pred)\n",
        "svm_precision = precision_score(y_test, svm_pred, average='weighted')\n",
        "svm_recall = recall_score(y_test, svm_pred, average='weighted')\n",
        "svm_conf_matrix = confusion_matrix(y_test, svm_pred)\n",
        "\n",
        "dt_accuracy = accuracy_score(y_test, dt_pred)\n",
        "dt_precision = precision_score(y_test, dt_pred, average='weighted')\n",
        "dt_recall = recall_score(y_test, dt_pred, average='weighted')\n",
        "dt_conf_matrix = confusion_matrix(y_test, dt_pred)\n",
        "\n",
        "rf_accuracy = accuracy_score(y_test, rf_pred)\n",
        "rf_precision = precision_score(y_test, rf_pred, average='weighted')\n",
        "rf_recall = recall_score(y_test, rf_pred, average='weighted')\n",
        "rf_conf_matrix = confusion_matrix(y_test, rf_pred)\n",
        "\n",
        "gb_accuracy = accuracy_score(y_test, gb_pred)\n",
        "gb_precision = precision_score(y_test, gb_pred, average='weighted')\n",
        "gb_recall = recall_score(y_test, gb_pred, average='weighted')\n",
        "gb_conf_matrix = confusion_matrix(y_test, gb_pred)\n",
        "\n",
        "xgb_accuracy = accuracy_score(y_test, xgb_pred)\n",
        "xgb_precision = precision_score(y_test, xgb_pred, average='weighted')\n",
        "xgb_recall = recall_score(y_test, xgb_pred, average='weighted')\n",
        "xgb_conf_matrix = confusion_matrix(y_test, xgb_pred)"
      ],
      "metadata": {
        "id": "VhNZnZigxYQT"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print The Results"
      ],
      "metadata": {
        "id": "8RE9DQWHxtQq"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print precision, recall, and accuracy for each model\n",
        "print(\"Logistic Regression:\")\n",
        "print(f\"The accuracy score of Logistic Regression is {lr_accuracy}, The Precision Score is {lr_precision},The Recall Score is {lr_recall}\")\n",
        "print(f\"The Confusion matrix is \\n{lr_conf_matrix}\")\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"Multinomial Naive Bayes:\")\n",
        "print(f\"The accuracy score of MultinomialNB is {mnb_accuracy}, The Precision Score is {mnb_precision},The Recall Score is {mnb_recall}\")\n",
        "print(f\"The Confusion matrix is \\n{mnb_conf_matrix}\")\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"Gaussian Naive Bayes:\")\n",
        "print(f\"The accuracy score of GaussianNB is {gnb_accuracy}, The Precision Score is {gnb_precision},The Recall Score is {gnb_recall}\")\n",
        "print(f\"The Confusion matrix is \\n{gnb_conf_matrix}\")\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"SVM:\")\n",
        "print(f\"The accuracy score of SVC is {svm_accuracy}, The Precision Score is {svm_precision},The Recall Score is {svm_recall}\")\n",
        "print(f\"The Confusion matrix is \\n{svm_conf_matrix}\")\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"Decision Trees:\")\n",
        "print(f\"The accuracy score of Decision Tree classifier is {dt_accuracy}, The Precision Score is {dt_precision},The Recall Score is {dt_recall}\")\n",
        "print(f\"The Confusion matrix is \\n{dt_conf_matrix}\")\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"Random Forests:\")\n",
        "print(f\"The accuracy score of Random Forest classifier is {rf_accuracy}, The Precision Score is {rf_precision},The Recall Score is {rf_recall}\")\n",
        "print(f\"The Confusion matrix is \\n{rf_conf_matrix}\")\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"Gradient Boosting Classifier:\")\n",
        "print(f\"The accuracy score of Gradient Boosting Classifier is {gb_accuracy}, The Precision Score is {gb_precision},The Recall Score is {gb_recall}\")\n",
        "print(f\"The Confusion matrix is \\n{gb_conf_matrix}\")\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"XGBoost Classifier:\")\n",
        "print(f\"The accuracy score of XGBoost Classifier is {xgb_accuracy}, The Precision Score is {xgb_precision},The Recall Score is {xgb_recall}\")\n",
        "print(f\"The Confusion matrix is \\n{xgb_conf_matrix}\")\n",
        "print(\"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8m5xlOex5Pg",
        "outputId": "30ff7e4f-aac7-4426-d94c-4cebb564be05"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression:\n",
            "The accuracy score of Logistic Regression is 0.9718992248062015, The Precision Score is 0.9724528699938659,The Recall Score is 0.9718992248062015\n",
            "The Confusion matrix is \n",
            "[[895   1]\n",
            " [ 28 108]]\n",
            "\n",
            "\n",
            "Multinomial Naive Bayes:\n",
            "The accuracy score of MultinomialNB is 0.9563953488372093, The Precision Score is 0.9624374427464473,The Recall Score is 0.9563953488372093\n",
            "The Confusion matrix is \n",
            "[[859  37]\n",
            " [  8 128]]\n",
            "\n",
            "\n",
            "Gaussian Naive Bayes:\n",
            "The accuracy score of GaussianNB is 0.8691860465116279, The Precision Score is 0.9179176426684793,The Recall Score is 0.8691860465116279\n",
            "The Confusion matrix is \n",
            "[[776 120]\n",
            " [ 15 121]]\n",
            "\n",
            "\n",
            "SVM:\n",
            "The accuracy score of SVC is 0.8953488372093024, The Precision Score is 0.9066061336051144,The Recall Score is 0.8953488372093024\n",
            "The Confusion matrix is \n",
            "[[896   0]\n",
            " [108  28]]\n",
            "\n",
            "\n",
            "Decision Trees:\n",
            "The accuracy score of Decision Tree classifier is 0.9554263565891473, The Precision Score is 0.9539719237801654,The Recall Score is 0.9554263565891473\n",
            "The Confusion matrix is \n",
            "[[884  12]\n",
            " [ 34 102]]\n",
            "\n",
            "\n",
            "Random Forests:\n",
            "The accuracy score of Random Forest classifier is 0.9195736434108527, The Precision Score is 0.9263922211400655,The Recall Score is 0.9195736434108527\n",
            "The Confusion matrix is \n",
            "[[896   0]\n",
            " [ 83  53]]\n",
            "\n",
            "\n",
            "Gradient Boosting Classifier:\n",
            "The accuracy score of Gradient Boosting Classifier is 0.9651162790697675, The Precision Score is 0.9643721350455067,The Recall Score is 0.9651162790697675\n",
            "The Confusion matrix is \n",
            "[[888   8]\n",
            " [ 28 108]]\n",
            "\n",
            "\n",
            "XGBoost Classifier:\n",
            "The accuracy score of XGBoost Classifier is 0.9631782945736435, The Precision Score is 0.962678492537747,The Recall Score is 0.9631782945736435\n",
            "The Confusion matrix is \n",
            "[[890   6]\n",
            " [ 32 104]]\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Logistic Regression is doing really well with an accuracy of {lr_accuracy} and precision of {lr_precision}, showing that it's the top performer in our email spam detection task.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGX2yBHWx8dN",
        "outputId": "6ae8c5d1-b46b-4436-9092-75857b590ffd"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression is doing really well with an accuracy of 0.9718992248062015 and precision of 0.9724528699938659, showing that it's the top performer in our email spam detection task.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Storing The Results in DataFrame"
      ],
      "metadata": {
        "id": "71w1vg9sx_Qx"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dictionary with evaluation results\n",
        "evaluation_data = {\n",
        "    'Model': ['Logistic Regression', 'MultinomialNB', 'GaussianNB', 'Decision Tree', 'SVM', 'Random Forest', 'Gradient Boosting', 'XGBoost'],\n",
        "    'Accuracy': [lr_accuracy, mnb_accuracy, gnb_accuracy, dt_accuracy, svm_accuracy, rf_accuracy, gb_accuracy, xgb_accuracy],\n",
        "    'Precision': [lr_precision, mnb_precision, gnb_precision, dt_precision, svm_precision, rf_precision, gb_precision, xgb_precision],\n",
        "   }\n",
        "\n",
        "# Create a DataFrame\n",
        "evaluation_df = pd.DataFrame(evaluation_data)\n",
        "\n",
        "# Sort the DataFrame based on Accuracy and Precision columns in descending order\n",
        "evaluation_df = evaluation_df.sort_values(by=['Accuracy', 'Precision'], ascending=False)\n",
        "\n",
        "# Display the sorted DataFrame\n",
        "print(evaluation_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8GsqVF1jyDUw",
        "outputId": "de93b204-a95a-4a85-f7fa-8a0332847b57"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 Model  Accuracy  Precision\n",
            "0  Logistic Regression  0.971899   0.972453\n",
            "6    Gradient Boosting  0.965116   0.964372\n",
            "7              XGBoost  0.963178   0.962678\n",
            "1        MultinomialNB  0.956395   0.962437\n",
            "3        Decision Tree  0.955426   0.953972\n",
            "5        Random Forest  0.919574   0.926392\n",
            "4                  SVM  0.895349   0.906606\n",
            "2           GaussianNB  0.869186   0.917918\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dlklfAuAyW2F"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}